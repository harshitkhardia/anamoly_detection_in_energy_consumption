{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from random import sample, seed, shuffle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA, KernelPCA, FastICA\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "#Checking the PyTorch version installed\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. From raw data to a tidy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Loading the raw data\n",
    "weather = pd.read_csv(\"/users/harsh/mtp/Detecting_anomalies_building_energy_usage/data/raw/weather.csv\")\n",
    "holidays = pd.read_csv(\"/users/harsh/mtp/Detecting_anomalies_building_energy_usage/data/raw/holidays.csv\")\n",
    "train = pd.read_csv(\"/users/harsh/mtp/Detecting_anomalies_building_energy_usage/data/raw/train.csv\")\n",
    "metadata = pd.read_csv(\"/users/harsh/mtp/Detecting_anomalies_building_energy_usage/data/raw/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 863, 869, 872, 875, 878, 881, 884, 887, 890, 896, 902, 911, 920,\n",
       "       925, 928, 930, 935, 938, '938', '234_203', '334_61', '38_0',\n",
       "       '38_1', '38_10106', '38_10107', '38_10108', '38_10109', '38_10110',\n",
       "       '38_10111', '38_10112', '38_10113', '38_10114', '38_10115',\n",
       "       '38_10116', '38_10117', '38_10118', '38_10119', '38_10120',\n",
       "       '38_10121', '38_10122', '38_10123', '38_10124', '38_10125',\n",
       "       '38_10126', '38_2', '38_52306', '38_52322', '38_52323', '38_52324',\n",
       "       '38_52325', '38_52326', '38_52327', '38_52328', '38_52329',\n",
       "       '38_52332', '38_52333', '38_52375', '38_52379', '38_52467',\n",
       "       '38_52468', '38_52469', '38_52470', '38_52471', '38_52472',\n",
       "       '38_52473', '38_52474', '38_52475', '38_52476', '38_52477',\n",
       "       '38_52478', '38_52479', '38_52480', '38_52481', '38_52482',\n",
       "       '38_56030', '38_56031', '38_56032', '38_56033', '38_56034',\n",
       "       '38_56727', '38_56728', '38_56729', '38_56730', '38_56731',\n",
       "       '38_56732', '38_56733', '38_56734', '38_56735', '38_56736',\n",
       "       '38_56737', '38_56738', '38_56739', '38_56740', '38_56741',\n",
       "       '38_56742', '38_56743', '38_56744', '38_56973', '38_59654',\n",
       "       '38_59804', '38_9678', '38_9679', '38_9680', '38_9681', '38_9682',\n",
       "       '38_9683', '38_9684', '38_9685', '38_9686', '38_9687', '38_9688',\n",
       "       '38_9689', '38_9693', '38_9694', '38_9695', '38_9696', '38_9697',\n",
       "       '38_9698', '38_9699', '38_9702', '38_9703', '38_9704', '38_9705',\n",
       "       '38_9706', '38_9707', '38_9708', '38_9709', '38_9710', '38_9711',\n",
       "       '38_9712', '38_9713', '38_9714', '38_9715', '38_9716', '38_9717',\n",
       "       '38_9718', '38_9719', '38_9720', '38_9725', '38_9726', '38_9727',\n",
       "       '38_9728', '38_9729', '38_9730', '38_9731', '38_9732', '38_9733',\n",
       "       '38_9737', '38_9738', '38_9739', '38_9740', '38_9741', '38_9742',\n",
       "       '38_9743', '38_9747', '38_9748', '38_9749', '38_9751', '38_9752',\n",
       "       '38_9753', '38_9754', '38_9755', '38_9756', '38_9757', '38_9758',\n",
       "       '38_9759', '38_9760', '38_9761', '38_9762', '38_9763', '38_9764',\n",
       "       '38_9765', '38_9766', '38_9787', '38_9788', '38_9789', '38_9790',\n",
       "       '38_9791', '38_9792', '38_9793', '38_9794', '38_9795', '38_9796',\n",
       "       '38_9797', '38_9798', '38_9799', '38_9801'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['meter_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['meter_id'] == '38_9686']\n",
    "train['Timestamp'] = pd.to_datetime(train['Timestamp'])\n",
    "train['Weekday'] = train['Timestamp'].dt.weekday\n",
    "train['Hour'] = train['Timestamp'].dt.hour\n",
    "train['Month'] = train['Timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some datasets have duplicates, this cell it take care of it\n",
    "train = train.groupby(['Timestamp']).first()\n",
    "train.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train['Values'].iloc[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# We take the difference of adjacent values of energy consumption since these values are cumulated \n",
    "train['ValuesDiff'] = 0\n",
    "train['ValuesDiff'].iloc[1:-1] = train['Values'].iloc[1:-1].values - train['Values'].iloc[:-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.loc[:1000,'ValuesDiff'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Timestamp'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "train.plot(y='ValuesDiff',x='Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Adding the Holidays column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['Date'] = train['Timestamp'].dt.strftime('%Y-%m-%d')\n",
    "holidays = pd.DataFrame(\n",
    "    holidays[holidays['site_id'] == \"038\"].groupby(['Date']).first())\n",
    "holidays.reset_index(level=0, inplace=True)\n",
    "train = train.merge(holidays, how='left', on = 'Date')\n",
    "del train['Date']\n",
    "train['Holiday'] = [isinstance(d, str)*1 for d in train['Holiday']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Adding the Temperature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Timestamp'] = pd.to_datetime(weather['Timestamp'])\n",
    "weather['Date'] = weather['Timestamp'].apply(lambda dt: datetime.datetime(dt.year, \n",
    "                                                                      dt.month, \n",
    "                                                                      dt.day, \n",
    "                                                                      dt.hour))\n",
    "weather = pd.DataFrame(\n",
    "    weather[weather['site_id'] == \"38\"].groupby(['Date'])['Temperature'].mean())\n",
    "weather.reset_index(level=0, inplace=True)\n",
    "train['Date'] = train['Timestamp'].apply(lambda dt: datetime.datetime(dt.year, \n",
    "                                                                      dt.month, \n",
    "                                                                      dt.day, \n",
    "                                                                      dt.hour))\n",
    "train = train.merge(weather, how='left', on='Date')\n",
    "del train['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Determining buckets of energy consumption (for the predictive model below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumption_label(x):\n",
    "    if x >= np.percentile(train['ValuesDiff'], 99):\n",
    "        return 'VeryHigh'\n",
    "    elif x >= np.percentile(train['ValuesDiff'], 95):\n",
    "        return 'High'\n",
    "    elif x >= np.percentile(train['ValuesDiff'], 80):\n",
    "        return 'MediumHigh'\n",
    "    elif x >= np.percentile(train['ValuesDiff'], 60):\n",
    "        return 'Medium'\n",
    "    elif x >= np.percentile(train['ValuesDiff'], 40):\n",
    "        return 'MediumLow'\n",
    "    elif x >= np.percentile(train['ValuesDiff'], 20):\n",
    "        return 'Low'\n",
    "    elif x >= np.percentile(train['ValuesDiff'], 5):\n",
    "        return 'VeryLow'\n",
    "    elif x >= np.percentile(train['ValuesDiff'], 1):\n",
    "        return 'StandBy'\n",
    "    else:\n",
    "        return 'Off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We chose to focus on the most recent years for our analysis, but it can surely run for all the dataset\n",
    "train = train[train['Timestamp'] > \"2016-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ValuesDiff'] = train['ValuesDiff'].fillna(-1)\n",
    "# Sometimes the meter resets, therefore we set the next value as NA, i.e., equal to -1\n",
    "train.loc[train['ValuesDiff'] < -1e+06, 'ValuesDiff'] = -1\n",
    "train['target'] = train['ValuesDiff'].apply(lambda row: consumption_label(row), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Handling temperature missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting indexes, this is important for the function that handles missing values\n",
    "train.reset_index(inplace=True)\n",
    "\n",
    "# Deleting some useless columns\n",
    "del train['index']\n",
    "del train['Unnamed: 0']\n",
    "del train['row_id']\n",
    "del train['site_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " def impute_values(indexes, x):\n",
    "    \"\"\"\n",
    "    This function will be used to fill na's in the temperature column. It will firstly find add \"blocks\" \n",
    "    of na's, i.e, sequence of consecutives na's. Then, it interpolates the missing values by using the \n",
    "    temperature values before and after the beggining of the na block.\n",
    "    \n",
    "    Arguments:\n",
    "        indexes: Pandas DataFrame of na's indexes\n",
    "        x: the Pandas DataFrame column with temperatures\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp = []\n",
    "    \n",
    "    blocks = []\n",
    "    \n",
    "    start_block = indexes[0]\n",
    "    \n",
    "    for idx in indexes:\n",
    "        \n",
    "        if start_block < 0:\n",
    "            start_block = idx\n",
    "        \n",
    "        if (idx+1) in indexes:\n",
    "            continue\n",
    "        else:\n",
    "            blocks.append([start_block, idx])\n",
    "            start_block = -1\n",
    "    \n",
    "    tmp = np.array([])\n",
    "    for begin, end in blocks:\n",
    "        \n",
    "        if begin == 0:\n",
    "            last_val = x[end+1]\n",
    "            next_val = x[end+1]\n",
    "        elif end == len(x)-1:\n",
    "            last_val = x[begin-1]\n",
    "            next_val = x[begin-1]\n",
    "        else:\n",
    "            last_val = x[begin-1]\n",
    "            next_val = x[end+1]\n",
    "\n",
    "        imputation = np.repeat((last_val+next_val)/2, end-begin +1)\n",
    "        \n",
    "        tmp = np.concatenate((tmp, imputation))\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>meter_id</th>\n",
       "      <th>Values</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>ValuesDiff</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:15:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.936775e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 00:30:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.937304e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.9375</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 00:45:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.937929e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>StandBy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.938486e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 01:15:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.939012e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.6250</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67619</th>\n",
       "      <td>2017-12-05 09:00:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>1.062107e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>368.3750</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VeryHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67620</th>\n",
       "      <td>2017-12-05 09:15:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>1.062506e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>398.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VeryHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67621</th>\n",
       "      <td>2017-12-05 09:30:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67622</th>\n",
       "      <td>2017-12-05 09:45:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67623</th>\n",
       "      <td>2017-12-05 10:00:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67624 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp meter_id        Values  Weekday  Hour  Month  \\\n",
       "0     2016-01-01 00:15:00  38_9686  7.936775e+05        4     0      1   \n",
       "1     2016-01-01 00:30:00  38_9686  7.937304e+05        4     0      1   \n",
       "2     2016-01-01 00:45:00  38_9686  7.937929e+05        4     0      1   \n",
       "3     2016-01-01 01:00:00  38_9686  7.938486e+05        4     1      1   \n",
       "4     2016-01-01 01:15:00  38_9686  7.939012e+05        4     1      1   \n",
       "...                   ...      ...           ...      ...   ...    ...   \n",
       "67619 2017-12-05 09:00:00  38_9686  1.062107e+06        1     9     12   \n",
       "67620 2017-12-05 09:15:00  38_9686  1.062506e+06        1     9     12   \n",
       "67621 2017-12-05 09:30:00  38_9686           NaN        1     9     12   \n",
       "67622 2017-12-05 09:45:00  38_9686           NaN        1     9     12   \n",
       "67623 2017-12-05 10:00:00  38_9686           NaN        1    10     12   \n",
       "\n",
       "       ValuesDiff  Holiday  Temperature    target  \n",
       "0         51.7500        1          5.0       Off  \n",
       "1         52.9375        1          5.0       Off  \n",
       "2         62.5000        1          5.0   StandBy  \n",
       "3         55.6875        1          5.0       Off  \n",
       "4         52.6250        1          5.0       Off  \n",
       "...           ...      ...          ...       ...  \n",
       "67619    368.3750        0          NaN  VeryHigh  \n",
       "67620    398.7500        0          NaN  VeryHigh  \n",
       "67621     -1.0000        0          NaN       Off  \n",
       "67622     -1.0000        0          NaN       Off  \n",
       "67623      0.0000        0          NaN       Off  \n",
       "\n",
       "[67624 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_temperatures = impute_values(train[train['Temperature'].isnull()].index, \n",
    "                                     train['Temperature'])\n",
    "train.loc[train['Temperature'].isnull(), 'Temperature'] = imputed_temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Pickling the dataset to gain some time for the next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train, open(os.path.join(os.getcwd(),'data\\\\train_prediction_38.pkl'), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open(os.path.join(os.getcwd(),'data\\\\train_prediction_38.pkl'), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Timestamp'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.plot(y='ValuesDiff',x='Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Preliminar steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['ValuesDiff', 'Holiday', 'Temperature', 'Weekday', 'Hour', 'Month']\n",
    "feature_scaler = StandardScaler()\n",
    "feature_scaler.fit(train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(df, sequence_length):\n",
    "    \"\"\"\n",
    "    This function builds a tidy dataset to be used as input to a LSTM. \n",
    "    It returns a tensor of the shape [nb_records, 3*sequence_length+2, feature_size] and a vector\n",
    "    of shape [nb_records] having the target values to predict.\n",
    "    \n",
    "    The main idea is to give the model an intraday pattern twice (two previous weeks) and an\n",
    "    same but incomplete pattern for the current week so that the model has to predict only the\n",
    "    last value of the pattern.\n",
    "    \n",
    "    Arguments:\n",
    "        df: Pandas DataFrame containing the energy consumption data\n",
    "        sequence_length: length of the pattern to recognize\n",
    "    \"\"\"\n",
    "    \n",
    "    target_labels = ['Off', 'StandBy', 'VeryLow', 'Low', 'MediumLow', 'Medium', 'MediumHigh', 'High','VeryHigh']\n",
    "    target_labels = np.array(target_labels)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(96*7*2, len(df) - sequence_length - 1):\n",
    "        for j in range(3):\n",
    "            if j == 0:\n",
    "                tmp = feature_scaler.transform(df[features].iloc[i:(i+sequence_length)])\n",
    "            else:\n",
    "                ts = feature_scaler.transform(df[features].iloc[(i-j*96*7):(i+sequence_length-j*96*7+1)])\n",
    "                tmp = np.concatenate((tmp, ts), axis=0)\n",
    "            \n",
    "        X.append(tmp)\n",
    "        y.append(np.where(target_labels == df['target'].iloc[i+sequence_length + 1])[0][0])\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66271, 26, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences, train_labels = generate_df(train, 8)\n",
    "train_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Splitting train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_val, _, _ = train_test_split(list(range(train_sequences.shape[0])), \n",
    "                                         np.zeros(train_sequences.shape[0]), \n",
    "                                         test_size=0.5, \n",
    "                                         random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_sequences = train_sequences[idx_train,:,:]\n",
    "rnn_labels = train_labels[idx_train]\n",
    "\n",
    "val_sequences = train_sequences[idx_val,:,:] \n",
    "val_labels = train_labels[idx_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Defining the predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runValidation(model_dict, cm_print = False):\n",
    "    model = WinticsRNN(hidden_size=hidden_size, \n",
    "                       features_size=len(features))\n",
    "    \n",
    "    model.load_state_dict(model_dict)    \n",
    "    model.eval()\n",
    "    \n",
    "    sequences = torch.FloatTensor(val_sequences)\n",
    "    sequences = autograd.Variable(sequences)\n",
    "    \n",
    "    labels_true = torch.LongTensor(val_labels)\n",
    "    labels_true = autograd.Variable(labels_true)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        sequences = sequences.cuda()\n",
    "        labels_true = labels_true.cuda()\n",
    "    \n",
    "    labels_predicted = model(sequences)\n",
    "    loss = loss_function(labels_predicted, labels_true)\n",
    "    \n",
    "    _, labels_predicted = labels_predicted.max(1)\n",
    "    labels_predicted = labels_predicted.data.cpu().numpy()\n",
    "    \n",
    "    if cm_print:\n",
    "        print(\"Current Validation loss: %.3f\" % loss.data.cpu().numpy())\n",
    "        print(confusion_matrix(labels_predicted, val_labels))\n",
    "    \n",
    "    return accuracy_score(labels_predicted, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WinticsRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, features_size):\n",
    "        super(WinticsRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.features_size = features_size\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.features_size, \n",
    "                          self.hidden_size, \n",
    "                          1, # This argument stands for the nb of layers \n",
    "                          dropout=0, \n",
    "                          batch_first = True)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_size, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        h0 = autograd.Variable(torch.zeros(1, x.size(0), self.hidden_size))\n",
    "        c0 = autograd.Variable(torch.zeros(1, x.size(0), self.hidden_size))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            h0, c0 = h0.cuda(), c0.cuda()\n",
    "\n",
    "        _, (x, _) = self.rnn(x, (h0, c0))\n",
    "        \n",
    "        x = torch.squeeze(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch losses: 1.51\n",
      "Epoch nb: 1\n",
      "Current Validation loss: 0.984\n",
      "[[   0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0]\n",
      " [ 184 1105 3146  926   91   18    0    0    0]\n",
      " [  18  100 1416 3524  824  192    1    0    0]\n",
      " [  16   59  381 2132 5398 1233   99    4    0]\n",
      " [   5   47   18   52  413 4624 1301  134   30]\n",
      " [   2    0    0    0    0  654 3517 1162  310]\n",
      " [   0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0]]\n",
      "Validation Accuracy: 0.61\n",
      "Epoch losses: 0.92\n",
      "Epoch losses: 0.84\n",
      "Epoch losses: 0.81\n",
      "Epoch losses: 0.79\n",
      "Epoch nb: 41\n",
      "Current Validation loss: 0.763\n",
      "[[   0    0    0    0    0    0    0    0    0]\n",
      " [ 188  661  228   37   22    4    0    0    0]\n",
      " [  21  576 3384 1317   85   14    0    0    0]\n",
      " [   7   59 1090 3345  771   15    0    0    0]\n",
      " [   7   15  237 1813 5032  406    1    0    0]\n",
      " [   0    0   22  122  816 5816  943   10    0]\n",
      " [   1    0    0    0    0  466 3800  541   50]\n",
      " [   1    0    0    0    0    0  174  749  290]\n",
      " [   0    0    0    0    0    0    0    0    0]]\n",
      "Validation Accuracy: 0.69\n",
      "Epoch losses: 0.76\n",
      "Epoch losses: 0.74\n",
      "Epoch losses: 0.72\n",
      "Epoch losses: 0.71\n",
      "Epoch nb: 81\n",
      "Current Validation loss: 0.718\n",
      "[[   0    0    0    0    0    0    0    0    0]\n",
      " [ 185  655  224   34   17    1    0    0    0]\n",
      " [  28  574 3143 1027   64    4    0    0    0]\n",
      " [   7   72 1465 4232 1172   11    0    0    0]\n",
      " [   3    7   93 1154 4614  395    0    0    0]\n",
      " [   0    1   36  187  857 5826  825    2    0]\n",
      " [   1    2    0    0    2  484 3907  422    8]\n",
      " [   1    0    0    0    0    0  186  870  272]\n",
      " [   0    0    0    0    0    0    0    6   60]]\n",
      "Validation Accuracy: 0.70\n",
      "Epoch losses: 0.69\n",
      "Epoch losses: 0.69\n",
      "Epoch losses: 0.68\n",
      "Epoch losses: 0.67\n",
      "Epoch nb: 121\n",
      "Current Validation loss: 0.688\n",
      "[[  36    7    0    0    0    0    0    0    0]\n",
      " [ 160  703  271   32   12    1    0    0    0]\n",
      " [  19  518 3030  947   45    1    0    0    0]\n",
      " [   6   77 1507 4217 1010   15    0    0    0]\n",
      " [   2    2  125 1325 4915  376    1    0    0]\n",
      " [   0    0   27  112  741 5812  708    0    0]\n",
      " [   1    4    1    1    3  516 4052  434    7]\n",
      " [   1    0    0    0    0    0  157  853  217]\n",
      " [   0    0    0    0    0    0    0   13  116]]\n",
      "Validation Accuracy: 0.72\n",
      "Epoch losses: 0.66\n",
      "Epoch losses: 0.65\n",
      "Epoch losses: 0.65\n",
      "Epoch losses: 0.64\n",
      "Epoch nb: 161\n",
      "Current Validation loss: 0.661\n",
      "[[  89   12    0    2    1    0    0    0    0]\n",
      " [ 111  673  242   21   11    1    0    0    0]\n",
      " [  14  546 3028  868   42    0    0    0    0]\n",
      " [   6   71 1559 4330  942   13    0    0    0]\n",
      " [   3    4  113 1345 5205  456    3    0    0]\n",
      " [   0    0   18   67  522 5723  639    0    0]\n",
      " [   1    5    1    1    3  528 4129  449    7]\n",
      " [   0    0    0    0    0    0  147  837  210]\n",
      " [   1    0    0    0    0    0    0   14  123]]\n",
      "Validation Accuracy: 0.73\n",
      "Epoch losses: 0.64\n",
      "Epoch losses: 0.63\n",
      "Epoch losses: 0.63\n",
      "Epoch losses: 0.63\n",
      "Epoch nb: 201\n",
      "Current Validation loss: 0.643\n",
      "[[  78    9    2    3    1    0    0    0    0]\n",
      " [ 122  629  180   14    6    0    0    0    0]\n",
      " [  14  593 3005  749   40    0    0    0    0]\n",
      " [   7   76 1666 4489  930   12    0    0    0]\n",
      " [   2    1   98 1338 5375  502    3    0    0]\n",
      " [   0    0   10   41  370 5592  539    0    0]\n",
      " [   1    3    0    0    4  615 4193  401    6]\n",
      " [   0    0    0    0    0    0  183  873  140]\n",
      " [   1    0    0    0    0    0    0   26  194]]\n",
      "Validation Accuracy: 0.74\n",
      "Epoch losses: 0.63\n",
      "Epoch losses: 0.62\n",
      "Epoch losses: 0.62\n",
      "Epoch losses: 0.62\n",
      "Epoch nb: 241\n",
      "Current Validation loss: 0.632\n",
      "[[  83    9    2    2    2    0    0    0    0]\n",
      " [ 117  670  223   18    6    0    0    0    0]\n",
      " [  15  572 3258 1001   55    0    0    0    0]\n",
      " [   6   56 1403 4488 1075   12    0    0    0]\n",
      " [   2    2   74 1093 5275  537    3    0    0]\n",
      " [   0    0    1   32  313 5705  665    0    0]\n",
      " [   1    2    0    0    0  467 4059  379    5]\n",
      " [   0    0    0    0    0    0  191  889  122]\n",
      " [   1    0    0    0    0    0    0   32  213]]\n",
      "Validation Accuracy: 0.74\n",
      "Epoch losses: 0.62\n",
      "Epoch losses: 0.62\n",
      "Epoch losses: 0.62\n",
      "Epoch losses: 0.62\n",
      "Epoch nb: 281\n",
      "Current Validation loss: 0.627\n",
      "[[  87    6    2    2    1    0    0    0    0]\n",
      " [ 114  677  229   18    7    1    0    0    0]\n",
      " [  15  579 3317 1071   56    0    0    0    0]\n",
      " [   5   47 1347 4481 1117   13    0    0    0]\n",
      " [   2    0   65 1035 5261  545    3    0    0]\n",
      " [   0    0    1   27  284 5684  644    0    0]\n",
      " [   1    2    0    0    0  478 4030  324    4]\n",
      " [   0    0    0    0    0    0  241  924   90]\n",
      " [   1    0    0    0    0    0    0   52  246]]\n",
      "Validation Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "nbEpochs = 282\n",
    "hidden_size = 80\n",
    "batch_size = 256\n",
    "\n",
    "net = WinticsRNN(hidden_size=hidden_size, \n",
    "                 features_size=len(features))\n",
    "\n",
    "#### Uncomment the following line if you want to retrain a previously saved model\n",
    "# net.load_state_dict(torch.load(\"../Models/LSTM_80_38\"))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.01)\n",
    "epoch_losses = []\n",
    "\n",
    "best_model = net.state_dict()\n",
    "epoch_acc_list = [] \n",
    "\n",
    "for ep in range(nbEpochs):\n",
    "\n",
    "    avg_loss = []        \n",
    "            \n",
    "    net.train()\n",
    "\n",
    "    for i in range(rnn_sequences.shape[0] // batch_size):\n",
    "        \n",
    "        X_batch = rnn_sequences[i*batch_size:(i+1)*batch_size, :, :]\n",
    "        y_batch = rnn_labels[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # [batch_size, sequence_length, features_size]\n",
    "        sequences = torch.FloatTensor(X_batch)\n",
    "        sequences = autograd.Variable(sequences)\n",
    "\n",
    "        labels_true = torch.LongTensor(y_batch)\n",
    "        labels_true = autograd.Variable(labels_true)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            sequences = sequences.cuda()\n",
    "            labels_true = labels_true.cuda()\n",
    "        \n",
    "        labels_predicted = net(sequences)        \n",
    "        \n",
    "        net.zero_grad()\n",
    "        loss = loss_function(labels_predicted, labels_true)\n",
    "        loss.backward()    \n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss.append(loss.data.cpu().numpy()) \n",
    "    \n",
    "    #<Early stopping>\n",
    "    epoch_acc = runValidation(net.state_dict())\n",
    "    epoch_acc_list.append(epoch_acc)\n",
    "\n",
    "    if max(epoch_acc_list) <= epoch_acc:\n",
    "        best_model = net.state_dict()\n",
    "\n",
    "    if max(epoch_acc_list)/1.2 > epoch_acc:\n",
    "        print(\"Training stopped by early stopping !\")\n",
    "        print(\"Validation MSE: %.2f\" % (max(epoch_acc_list)))\n",
    "        plt.plot(epoch_acc_list)\n",
    "        plt.show()\n",
    "        break\n",
    "    #</Early stopping>\n",
    "    \n",
    "    if ep % 10 == 1:     \n",
    "        print(\"Epoch losses: %.2f\" % (np.mean(epoch_losses)))\n",
    "        if ep % 40 == 1:\n",
    "            print(\"Epoch nb: {}\".format(ep))\n",
    "            \n",
    "            print(\"Validation Accuracy: %.2f\" % runValidation(net.state_dict(), True))\n",
    "            \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = param_group['lr'] * 0.8\n",
    "  \n",
    "        epoch_losses = []\n",
    "            \n",
    "    epoch_losses.append(np.mean(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, os.path.join(os.getcwd(),'data\\\\Model\\\\LSTM_80_38\\\\38.pth'))\n",
    "best_model = torch.load(os.path.join(os.getcwd(),'data\\\\Model\\\\LSTM_80_38\\\\38.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(os.path.join(os.getcwd(),'data\\\\Model\\\\LSTM_80_38\\\\38.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Evaluating the entropy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(model_dict, sequences, labels):\n",
    "    \"\"\"\n",
    "    This function returns (i) the labels predicted by the model as well as (ii) the entropy \n",
    "    of predictions, which will serve as an indicator of the prediction's confidence.\n",
    "    Small entropies mean that the model is sure of what it is predicting, regardless\n",
    "    the target value.\n",
    "    \n",
    "    Arguments:\n",
    "        model_dict: PyTorch model dictionary, i.e., the output of net.state_dict()\n",
    "        sequences: RNN inputs, i.e., tensors of the form [nb_records, 3*sequence_length+2, feature_size]\n",
    "        labels: Target values (only used for some metric evaluation)\n",
    "    \"\"\"\n",
    "    model = WinticsRNN(hidden_size=hidden_size, \n",
    "                       features_size=len(features))\n",
    "    \n",
    "    model.load_state_dict(model_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    sequences = torch.FloatTensor(sequences)\n",
    "    sequences = autograd.Variable(sequences)\n",
    "    \n",
    "    labels_true = torch.LongTensor(labels)\n",
    "    labels_true = autograd.Variable(labels_true)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        sequences = sequences.cuda()\n",
    "        labels_true = labels_true.cuda()\n",
    "\n",
    "    labels_predicted = model(sequences)\n",
    "    \n",
    "    entropy = [exp_logits/torch.sum(exp_logits) for exp_logits in torch.exp(labels_predicted)]\n",
    "    entropy = [-torch.log(probs).dot(probs) for probs in entropy]\n",
    "    entropy = np.array([e.data.cpu().numpy() for e in entropy])\n",
    "    \n",
    "    _, labels_predicted = labels_predicted.max(1)\n",
    "    labels_predicted = labels_predicted.data.cpu().numpy()\n",
    "    \n",
    "    print(\"Dataset accuracy: %.3f\" % accuracy_score(labels_predicted, labels))\n",
    "    cm = confusion_matrix(labels_predicted, labels)\n",
    "    extended_diagonal = cm.trace()+cm[1:, :-1].trace()+cm[:-1, 1:].trace()\n",
    "    extended_diagonal_2 = extended_diagonal+cm[2:, :-2].trace()+cm[:-2, 2:].trace()\n",
    "    \n",
    "    print(\"Dataset extended accuracy (max gap 1): %.3f\" % (extended_diagonal/np.sum(cm)))\n",
    "    print(\"Dataset extended accuracy (max gap 2): %.3f\" % (extended_diagonal_2/np.sum(cm)))\n",
    "    \n",
    "    return labels_predicted, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset accuracy: 0.752\n",
      "Dataset extended accuracy (max gap 1): 0.993\n",
      "Dataset extended accuracy (max gap 2): 0.999\n"
     ]
    }
   ],
   "source": [
    "# Calculating the entropies for the training dataset\n",
    "overconsumption_train, entropy_train = entropy(best_model, rnn_sequences, rnn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset accuracy: 0.746\n",
      "Dataset extended accuracy (max gap 1): 0.992\n",
      "Dataset extended accuracy (max gap 2): 0.999\n"
     ]
    }
   ],
   "source": [
    "# Calculating the entropies for the test dataset\n",
    "overconsumption_val, entropy_val = entropy(best_model, val_sequences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column 'entropy' in the original dataset \n",
    "train['entropy'] = 3.0\n",
    "train.loc[96*7*2+8+1+np.array(idx_val),'entropy'] = entropy_val[:]\n",
    "train.loc[96*7*2+8+1+np.array(idx_train), 'entropy'] = entropy_train[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column 'predicted' in the original dataset\n",
    "target_labels = ['Off', 'StandBy', 'VeryLow', 'Low', 'MediumLow', 'Medium', 'MediumHigh', 'High','VeryHigh']\n",
    "train['predicted'] = \"None\"\n",
    "train.loc[96*7*2+8+1+np.array(idx_val), 'predicted'] = [target_labels[v] for v in overconsumption_val]\n",
    "train.loc[96*7*2+8+1+np.array(idx_train), 'predicted'] = [target_labels[v] for v in overconsumption_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Determining the anomaly score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gap(row):\n",
    "    \"\"\"\n",
    "    This function returns the number of buckets lying between the prediction and the target value.\n",
    "    It will be applied to all the main dataset's lines.\n",
    "    \n",
    "    Arguments:\n",
    "        row: row of the dataset.\n",
    "    \"\"\"\n",
    "    if row['predicted'] in target_labels:\n",
    "        idx_pred = np.where(np.array(target_labels) == row['predicted'])[0][0]\n",
    "        idx_true = np.where(np.array(target_labels) == row['target'])[0][0]\n",
    "\n",
    "        return idx_true - idx_pred\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gap'] = train.apply(lambda row: get_gap(row), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CRITERIA : the anomaly score\n",
    "\n",
    "The main motivation for that anomaly score is to catch two behaviours :\n",
    "\n",
    "    - Low entropy and low prediction gap:\n",
    "        The model is sure of what it is predicting, and still, there is a gap. This effect\n",
    "        increases the risk that the current measurement is actually an anomaly.\n",
    "    - Moderate enropy and high prediction gap:\n",
    "        If the gap is somehow higher than what the entropy measurement is expecting,\n",
    "        then the this energy measurement is a potential anomaly.\n",
    "\n",
    "Since there are 9 buckets, the maximum entropy we can possibly get is ln(9), which is about 2.2.\n",
    "\n",
    "Let's consider an arbitrary prediction. Suppose that its entropy is equal to 0.69, then, \n",
    "the mass of probabilities is very likely distributed to only 2 buckets (because ln(2) is about 0.69). \n",
    "Suppose that the gap between the prediction and the target value is 3. We have then a suspicious\n",
    "energy measurement: the probabilities are very high for only two buckets (probably one next \n",
    "to the other), and still the target value is 3 buckets away from the prediction.\n",
    "\n",
    "The same logic can be drawn for all gaps. I came up with the following formula:\n",
    "$$gap*exp(ln(9)-entropy)$$\n",
    "\n",
    "It will have high absolute values whenever something unexpected happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['criteria'] = train['gap']*np.exp(3 - train['entropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 Rule-based approach (Percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['temp_bucket'] = train['Temperature'].apply(lambda row: np.round(row/5)*5)\n",
    "train['working_day'] = (train['Weekday'] < 5)&(train['Holiday'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentile(row):\n",
    "    \"\"\"\n",
    "    This function returns the percentile of the energy consumption measurement with respect\n",
    "    to (i) the Temperature, (ii) the type of day and (iii) the hour.\n",
    "    \n",
    "    Arguments:\n",
    "        row: row of the dataset.\n",
    "    \"\"\"\n",
    "    bucket = row['temp_bucket']\n",
    "    weekday = row['working_day']\n",
    "    hour = row['Hour']\n",
    "    \n",
    "    cond = (train['temp_bucket'] == bucket)&(train['working_day'] == weekday)&(train['Hour'] == hour)    \n",
    "    range_of_values = train.loc[cond, 'ValuesDiff']\n",
    "    \n",
    "    return stats.percentileofscore(range_of_values, row['ValuesDiff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['percentile'] = train.apply(lambda row: get_percentile(row), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Rule-based approach (Checking the context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    " def check_context(idx):\n",
    "    \"\"\"\n",
    "    The main idea of that function is to detect and eliminate anomalies that come from abnormal\n",
    "    contexts. For instance, if there is a conference takes place in the building for an entire\n",
    "    week, the energy consumption levels will be higher than the 'normal' days but it won't\n",
    "    necessarily be classified as overconsumption. So the idea is to detect these kind of weeks \n",
    "    and ignore any alarm that the predictive model might throw in that period of time.\n",
    "    \n",
    "    This function checks whether the pattern of a certain meter neighbourhood value is high \n",
    "    across the entire week. It compares the pattern percentiles for the precedent week against\n",
    "    the two former weeks. It returns the number of days it went higher.\n",
    "    \n",
    "    Arguments:\n",
    "        idx: index of the meter measurement, i.e., dataset row.\n",
    "    \"\"\"\n",
    "    ans = 0\n",
    "    \n",
    "    for j in range(7):\n",
    "        week_n   = train.loc[idx-8-j*96       :idx+8-j*96, 'percentile'].mean()\n",
    "        week_n_1 = train.loc[idx-8-j*96-96*7*1:idx+8-j*96-96*7*1, 'percentile'].mean()\n",
    "        week_n_2 = train.loc[idx-8-j*96-96*7*2:idx+8-j*96-96*7*2, 'percentile'].mean()\n",
    "        \n",
    "        ans += (week_n > week_n_1 + 10)*1 + (week_n > week_n_2 + 10)*1\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an illustration of what can be detected by this model\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "begin = 55234-96\n",
    "end = 55234+1+96\n",
    "consumption = train.loc[begin:end, 'ValuesDiff'].values - train.loc[begin:end, 'ValuesDiff'].min()\n",
    "consumption = 100*consumption/(train.loc[begin:end, 'ValuesDiff'].max()-train.loc[begin:end, 'ValuesDiff'].min())\n",
    "slide = 55234\n",
    "ax1.plot(train.loc[begin:end, 'percentile'].values)\n",
    "ax1.plot(consumption, color = \"green\")\n",
    "ax1.set_ylim([0, 100])\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train.loc[begin:end, 'criteria'].values, color=\"red\", linestyle=\":\", linewidth=3)\n",
    "ax2.set_ylim([-16, 16])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 The algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two modifications have been done for this site since there is no measurement with criteria > 11.\n",
    "\n",
    "<li>Criteria Threshold: 6 (instead of 11)</li>\n",
    "<li>Anomaly duration: at least half hour (instead of at least an hour) </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "train['is_abnormal'] = False\n",
    "\n",
    "# Detecting the beggining of anomalies (Prediction-Based approach)\n",
    "train.loc[train['criteria']>6, 'is_abnormal'] = True\n",
    "\n",
    "# Filtering process (Rule-based approach)\n",
    "for idx in train[train['is_abnormal']].index:\n",
    "    \n",
    "    # Eliminating abnormal energy consumption contexts\n",
    "    if check_context(idx) > 8:\n",
    "        train.loc[idx, 'is_abnormal'] = False\n",
    "        continue\n",
    "        \n",
    "    # Eliminating low percentile anomalies\n",
    "    if train.loc[idx, 'percentile'] < 90:\n",
    "        train.loc[idx, 'is_abnormal'] = False\n",
    "        continue\n",
    "    \n",
    "    # Eliminating anomalies that come just after na values\n",
    "    if train.loc[idx-5:idx-1, 'Values'].min() < 0:\n",
    "        train.loc[idx, 'is_abnormal'] = False\n",
    "        continue\n",
    "    \n",
    "    # Anomalies should begin just after a ascending percentile pattern\n",
    "    if train.loc[idx-5:idx-1, 'percentile'].mean() >= 80:\n",
    "        train.loc[idx, 'is_abnormal'] = False\n",
    "\n",
    "# Extending the duration of the anomalies\n",
    "for idx in train[train['is_abnormal']].index:\n",
    "    k=0\n",
    "    moving_average = train.loc[idx, 'percentile']\n",
    "    while (moving_average >= 80):\n",
    "        train.loc[idx+k, 'is_abnormal'] = True\n",
    "        k+=1\n",
    "        moving_average = 0.2*moving_average + 0.8*train.loc[idx+k, 'percentile']\n",
    "\n",
    "    # Eliminating anomalies that last less than half an hour\n",
    "    if k < 2:\n",
    "        train.loc[idx:idx+k, 'is_abnormal'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['is_abnormal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10 Illustration of the anomalies found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "anamolyno=12\n",
    "begin = 55234-48\n",
    "end = 55234+1+48\n",
    "ax1.plot(train.loc[begin:end, 'percentile'])\n",
    "ax1.plot(train[train['is_abnormal']].loc[begin:end, 'percentile'], color = \"green\", linewidth=10, linestyle=\":\")\n",
    "ax1.set_ylim([0, 100])\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train.loc[begin:end, 'criteria'], color=\"red\")\n",
    "ax2.set_ylim([-16, 16])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "anamolyno=2\n",
    "fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "slide = train.loc[train['is_abnormal']==True].index[anamolyno]\n",
    "begin = slide-96\n",
    "end = slide+1+96\n",
    "consumption = train.loc[begin:end, 'ValuesDiff'].values - train.loc[begin:end, 'ValuesDiff'].min()\n",
    "consumption = 100*consumption/(train.loc[begin:end, 'ValuesDiff'].max()-train.loc[begin:end, 'ValuesDiff'].min())\n",
    "timestamp=train.loc[begin:end,'Timestamp']\n",
    "ax1.plot(timestamp,train.loc[begin:end, 'percentile'].values)\n",
    "ax1.plot(timestamp,consumption, color = \"green\")\n",
    "ax1.set_ylim([0, 100])\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(timestamp,train.loc[begin:end, 'criteria'].values, color=\"red\", linestyle=\":\", linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Timestamp'>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.plot(x='Timestamp',y='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>meter_id</th>\n",
       "      <th>Values</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>ValuesDiff</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>target</th>\n",
       "      <th>entropy</th>\n",
       "      <th>predicted</th>\n",
       "      <th>gap</th>\n",
       "      <th>criteria</th>\n",
       "      <th>temp_bucket</th>\n",
       "      <th>working_day</th>\n",
       "      <th>percentile</th>\n",
       "      <th>is_abnormal</th>\n",
       "      <th>v</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:15:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.936775e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Off</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 00:30:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.937304e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.9375</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Off</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.673797</td>\n",
       "      <td>False</td>\n",
       "      <td>121.474940</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 00:45:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.937929e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>StandBy</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5.347594</td>\n",
       "      <td>False</td>\n",
       "      <td>1128.984652</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.938486e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Off</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5.612245</td>\n",
       "      <td>False</td>\n",
       "      <td>-606.993750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 01:15:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>7.939012e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.6250</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Off</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>False</td>\n",
       "      <td>-289.407969</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67619</th>\n",
       "      <td>2017-12-05 09:00:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>1.062107e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>368.3750</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>VeryHigh</td>\n",
       "      <td>1.044054</td>\n",
       "      <td>VeryHigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>80.434783</td>\n",
       "      <td>False</td>\n",
       "      <td>-997.251568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67620</th>\n",
       "      <td>2017-12-05 09:15:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>1.062506e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>398.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>VeryHigh</td>\n",
       "      <td>1.051636</td>\n",
       "      <td>VeryHigh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>92.391304</td>\n",
       "      <td>False</td>\n",
       "      <td>3287.962335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67621</th>\n",
       "      <td>2017-12-05 09:30:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>Off</td>\n",
       "      <td>1.057056</td>\n",
       "      <td>VeryHigh</td>\n",
       "      <td>-8</td>\n",
       "      <td>-55.834158</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.630435</td>\n",
       "      <td>False</td>\n",
       "      <td>100.250784</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67622</th>\n",
       "      <td>2017-12-05 09:45:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>Off</td>\n",
       "      <td>1.055175</td>\n",
       "      <td>VeryHigh</td>\n",
       "      <td>-8</td>\n",
       "      <td>-55.939254</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.630435</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67623</th>\n",
       "      <td>2017-12-05 10:00:00</td>\n",
       "      <td>38_9686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>Off</td>\n",
       "      <td>1.107904</td>\n",
       "      <td>High</td>\n",
       "      <td>-7</td>\n",
       "      <td>-46.432782</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67624 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp meter_id        Values  Weekday  Hour  Month  \\\n",
       "0     2016-01-01 00:15:00  38_9686  7.936775e+05        4     0      1   \n",
       "1     2016-01-01 00:30:00  38_9686  7.937304e+05        4     0      1   \n",
       "2     2016-01-01 00:45:00  38_9686  7.937929e+05        4     0      1   \n",
       "3     2016-01-01 01:00:00  38_9686  7.938486e+05        4     1      1   \n",
       "4     2016-01-01 01:15:00  38_9686  7.939012e+05        4     1      1   \n",
       "...                   ...      ...           ...      ...   ...    ...   \n",
       "67619 2017-12-05 09:00:00  38_9686  1.062107e+06        1     9     12   \n",
       "67620 2017-12-05 09:15:00  38_9686  1.062506e+06        1     9     12   \n",
       "67621 2017-12-05 09:30:00  38_9686           NaN        1     9     12   \n",
       "67622 2017-12-05 09:45:00  38_9686           NaN        1     9     12   \n",
       "67623 2017-12-05 10:00:00  38_9686           NaN        1    10     12   \n",
       "\n",
       "       ValuesDiff  Holiday  Temperature    target   entropy predicted  gap  \\\n",
       "0         51.7500        1          5.0       Off  3.000000      None    0   \n",
       "1         52.9375        1          5.0       Off  3.000000      None    0   \n",
       "2         62.5000        1          5.0   StandBy  3.000000      None    0   \n",
       "3         55.6875        1          5.0       Off  3.000000      None    0   \n",
       "4         52.6250        1          5.0       Off  3.000000      None    0   \n",
       "...           ...      ...          ...       ...       ...       ...  ...   \n",
       "67619    368.3750        0         -5.7  VeryHigh  1.044054  VeryHigh    0   \n",
       "67620    398.7500        0         -5.7  VeryHigh  1.051636  VeryHigh    0   \n",
       "67621     -1.0000        0         -5.7       Off  1.057056  VeryHigh   -8   \n",
       "67622     -1.0000        0         -5.7       Off  1.055175  VeryHigh   -8   \n",
       "67623      0.0000        0         -5.7       Off  1.107904      High   -7   \n",
       "\n",
       "        criteria  temp_bucket  working_day  percentile  is_abnormal  \\\n",
       "0       0.000000          5.0        False    0.534759        False   \n",
       "1       0.000000          5.0        False    2.673797        False   \n",
       "2       0.000000          5.0        False    5.347594        False   \n",
       "3       0.000000          5.0        False    5.612245        False   \n",
       "4       0.000000          5.0        False    2.040816        False   \n",
       "...          ...          ...          ...         ...          ...   \n",
       "67619   0.000000         -5.0         True   80.434783        False   \n",
       "67620   0.000000         -5.0         True   92.391304        False   \n",
       "67621 -55.834158         -5.0         True    1.630435        False   \n",
       "67622 -55.939254         -5.0         True    1.630435        False   \n",
       "67623 -46.432782         -5.0         True    1.449275        False   \n",
       "\n",
       "                 v    t  \n",
       "0              NaN  0.0  \n",
       "1       121.474940  0.0  \n",
       "2      1128.984652  0.0  \n",
       "3      -606.993750  0.0  \n",
       "4      -289.407969  0.0  \n",
       "...            ...  ...  \n",
       "67619  -997.251568  0.0  \n",
       "67620  3287.962335  0.0  \n",
       "67621   100.250784 -0.0  \n",
       "67622    -0.000000 -0.0  \n",
       "67623    -0.000000  0.0  \n",
       "\n",
       "[67624 rows x 20 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['v']=train['ValuesDiff'].pct_change()*100*train['ValuesDiff']\n",
    "train.loc[train['is_abnormal']==True,'t']=1\n",
    "train.loc[train['is_abnormal']==False,'t']=0\n",
    "train['t']=train['t']*train['ValuesDiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "anamolyno=12\n",
    "fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "ax1.plot(train['Timestamp'],train['ValuesDiff'],color = \"green\")\n",
    "#ax1.set_ylim([0, 100])\n",
    "ax2 = ax1.twinx()\n",
    "ax2.scatter(train['Timestamp'],train['t'], color=\"red\",)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
